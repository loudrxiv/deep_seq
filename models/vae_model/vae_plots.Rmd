---
title: "Visualize Latent Embedding"
output: html_notebook
---

# Load Libraries
```{r}
library(reticulate)
library(tensorflow)
library(tfdatasets)
library(BSgenome.Hsapiens.UCSC.hg38)
library(ggplot2)
library(keras)
library(tfaddons)
library(tfruns)
library(tfdatasets)
```
# Load Example Data
```{r}
DIR_EX          <- "~/data/seq_vae/for_testing/"
DIR_MODEL       <- "~/seq_vae/src/models/vae_model/"
DIR_PLOTS       <- "~/plots/seq_vae/vae_model/testing_vae/"
DIR_TENSORBOARD <- "~/plots/seq_vae/vae_model/tensorboards/"

#- Data
train <- readRDS(paste0(DIR_EX, "ex_train.rds"))
test  <- readRDS(paste0(DIR_EX, "ex_test.rds"))
val   <- readRDS(paste0(DIR_EX, "ex_val.rds"))

#- Models
encoder <- load_model_tf(paste0(DIR_MODEL, "encoder"))
decoder <- load_model_tf(paste0(DIR_MODEL, "decoder"))
vae     <- load_model_tf(paste0(DIR_MODEL, "vae"))
```
# Plot Reconstruction
```{r}
#- original sequence
s1h_ori = ds_test[1:3,] |> tf$one_hot(4L) |> as.array()
s1h_rec = vae     |> predict(s1h_ori)
s1h_emb = encoder |> predict(s1h_ori)

#- look only at a part of the sequence, otherwise too long.
N = 300
y_true    <- as.matrix(s1h_ori[1,1:(N*16),]) |> t()
y_pred    <- as.matrix(s1h_rec[1,1:(N*16),] )|> t()
y_pred_b  <- apply(y_pred, 2, function(x) { res = rep(0,4) ; res[which.max(x)] = 1; res})
y_emb     <- as.matrix(s1h_emb[1,1:(N),] )

par(mfcol = c(1,4), mai=rep(.1,4))

#- Create & Save Images
ys=c("true","emb","pred","diff")
for(i in 1:length(ys)) {
  pdf(paste(DIR_PLOTS,"y_",ys[i],".pdf",sep = ""))

  if("true" %in% ys[i]) {
  image(y_true, axes=FALSE, main="True Labels")
  }
  else if("emb" %in% ys[i]) {
  image(t(y_emb), axes=FALSE, main="Embedded Labels")
  }
  else if("pred" %in% ys[i]) {
  image(y_pred, axes=FALSE, main="Predicted Labels")
  } 
  else {
  image(y_true - y_pred_b, axes=FALSE, main="Difference In Labels")
  }
  dev.off()
}
```

# Visualize Latent embedding
```{r}
tensorboard(log_dir = paste0(DIR_TENSORBOARD, "2022-05-03 12:56:33"))
```
```{r}

# Want to capture same clutering as original image, if not denser
# as there should be less noise

#- Libraries
library(Rtsne)

#- original sequence
s1h_ori = ds_test[1:3,] |> tf$one_hot(4L) |> as.array()
s1h_rec = vae     |> predict(s1h_ori)
s1h_emb = encoder |> predict(s1h_ori)

set.seed(1) # for reproducibility

# 3 X 16384 X 4 ->  3 X 16384 X 4
input <- s1h_ori[1:dim(s1h_ori)[1],1:dim(s1h_ori)[2],1]

# perplexity    numeric; Perplexity parameter (should not be bigger
#              than 3 * perplexity < nrow(X) - 1, see details for
#              interpretation)
tsne <- Rtsne(input,
              dims = 2,
              perplexity=0.6,
              verbose=TRUE,
              max_iter = 500
              )

colors <- rainbow(length(c(0,1)))
plot(tsne,tsne)
```