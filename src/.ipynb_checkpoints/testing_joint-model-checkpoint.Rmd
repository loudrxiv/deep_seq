---
title: "testing_joint-model"
output: html_notebook
---

# Libraries & Constants
```{r}
library(reticulate)
library(tensorflow)
library(tfdatasets)
library(BSgenome.Hsapiens.UCSC.hg38)
library(keras)
library(tfaddons)

np <- reticulate::import("numpy")

if(! is_keras_available(version = NULL)) 
    stop("No Keras.")
 
set.seed(24213)
HOCOMOCO_DAT <- "~/data/seq_vae/hocomoco/human/hoc_pwms_hg_16.rdat"
IE_DAT       <- "/lab/dat/ienhancer_el/04-02-2022/ienhancer_el_benchmark_labeled.fa.gz"

#= Plotting
DIR_PLOTS       <- "~/plots/seq_vae/vae_model/"
DIR_TENSORBOARD <- paste0(DIR_PLOTS, "tensorboards/")

DIR_ENCODER      <- "~/seq_vae/src/models/vae_model/encoder"
encoder          <- load_model_tf(DIR_ENCODER)
```

# Functions
```{r}
filterSafetyCheck = function(the_filters) {
    if(any(lapply(the_filters, is.matrix) |> unlist() == FALSE))            
        stop("filters invalid\n")
    if(any(lapply(the_filters, ncol) |> unlist() != ncol(the_filters[[1]]))) 
        stop("filters invalid\n")
    if(any(lapply(the_filters, nrow) |> unlist() != nrow(the_filters[[1]]))) 
        stop("filters invalid\n")
}
reconstruction_loss = function(y_true, y_pred){
    return(
        tf$math$reduce_mean(
            tf$keras$metrics$binary_crossentropy(y_true,
                                                 y_pred,
                                                 label_smoothing = 1E-5)))
}
kl_divergence = function(z_mean, z_logVar) {
    return( -0.5 * tf$reduce_mean(z_logVar - tf$square(z_mean) - 
                                      tf$exp(z_logVar) + 1) )
}
make_ints = function(seqs){
    tmp      <- as.matrix(seqs)
    seqs_int <- apply(tmp, 2,function(x) as.factor(x) |> as.integer() - 1L)
    return(seqs_int)
}
make_1h = function(seqs){
    seq_ints <- make_ints(seqs)
    seqs_1h  <- tf$one_hot(seqs_int,4L) |> as.array()
    return(seqs_1h)
}
```
# Load Data
```{r}
#= Benchmark data
ie_dat   <- Biostrings::readDNAStringSet(IE_DAT)
ie_dat_label  <- ie_dat |> names() |> stringr::str_detect('strong|weak') |> as.integer()

#= Motif data
#== Generate Tensor (PWSM)
my_filters <- readRDS(HOCOMOCO_DAT) |> lapply(as.matrix)
filterSafetyCheck(my_filters)
filter_tensor <- my_filters |> 
    unlist() |> 
    array(dim = c( nrow(my_filters[[1]]), 4, length(my_filters)))

#== Tile Sequences
mt = GenomicRanges::tileGenome(BSgenome.Hsapiens.UCSC.hg38::Hsapiens |> 
                                   seqinfo() |> keepStandardChromosomes(), 
                               tilewidth=16*57425,
                               cut.last.tile.in.chrom = TRUE)
#== Format Sequences
sqs        = Biostrings::getSeq(Hsapiens,mt) 
names(sqs) = mt |> as.character()
nNs        = Biostrings::vcountPattern('N',sqs)
sqs        = sqs[nNs == 0]
sqs        = sqs[width(sqs) == 16*57425]

#= Concatenate two datatypes
sqs <- xscat(sqs, ie_dat)

#= Split into train & test sets
tst_size      = length(sqs) %/% 5
val_size      = (length(sqs) * 0.8) %/% 5
shuff         = sample(seq_len(sqs |> length() ))
ssqs          = sqs[shuff]
sie_dat_label = ie_dat_label[shuff]
```

```{r} 
# get data
ds_test       = ssqs[1:tst_size] |> make_ints()
y_test        = sie_dat_label[1:tst_size]
ssqs          = ssqs[-(1:tst_size)]
sie_dat_label = sie_dat_label[-(1:tst_size)]

# concat
test_set <- list("data"=ds_test, "labels"=y_test)
```

```{R}
# make tfdata
mds_test = tensor_slices_dataset(test_set)                          |>
            dataset_shuffle( buffer_size = 10000L,
                             reshuffle_each_iteration=TRUE)         |>
            dataset_batch(64, drop_remainder = TRUE)                |>
            dataset_map(map_func = function(x) {
                y = x$labels
                #x = tf$one_hot(x[1]$data, 4L)
                x = tf$one_hot(x$data, 4L)
                list(x,y)
            })                                                      |>
            dataset_repeat()                                        |>
            dataset_prefetch_to_device(device = '/gpu:0',
                                       buffer_size = tf$data$AUTOTUNE)

```

```{r}
ds_val        = ssqs[1:val_size] |> make_ints()
y_val         = sie_dat_label[1:val_size]

ssqs          = ssqs[-(1:val_size)]
sie_dat_label = sie_dat_label[-(1:val_size)]

# concat
val_set <- list("data"=ds_val, "labels"=y_val)

# make tfdataset
mds_val = tensor_slices_dataset(val_set)                          |>
            dataset_map(map_func = function(x) {
                y = x$labels
                #x = tf$one_hot(x[1]$data, 4L)
                x = tf$one_hot(x$data, 4L)
                list(x,y)
            })                                                      |>
            dataset_shuffle( buffer_size = 10000L,
                             reshuffle_each_iteration=TRUE)         |>
            dataset_batch(64, drop_remainder = TRUE)                |>
            dataset_repeat()                                        |>
            dataset_prefetch_to_device(device = '/gpu:0',
                                       buffer_size = tf$data$AUTOTUNE)
```

```{r}
ds_train      = ssqs |> make_ints()
y_train       = sie_dat_label

# concat
train_set <- list("data"=ds_train, "labels"=y_train)

# make tfdata
mds_train = tensor_slices_dataset(train_set)                        |>
            dataset_map(map_func = function(x) {
                y = x$labels
                #x = tf$one_hot(x[1]$data, 4L)
                x = tf$one_hot(x$data, 4L)
                list(x,y)
            })                                                      |>
            dataset_shuffle( buffer_size = 10000L,
                             reshuffle_each_iteration=TRUE)         |>
            dataset_batch(64, drop_remainder = TRUE)                |>
            dataset_repeat()                                        |>
            dataset_prefetch_to_device(device = '/gpu:0',
                                       buffer_size = tf$data$AUTOTUNE)
```

# Reconstruction
```{R}
mod_vae = mod_vae |> compile(loss="binary_crossentropy",
                             optimizer = keras$optimizers$Adamax(),
                             metrics    = list(tf$keras$metrics$BinaryAccuracy(name="acc"),
                                               tf$keras$metrics$AUC(name="auroc"),
                                               tf$keras$metrics$AUC(name="auprc", curve="PR")))

early_stopping = tf$keras$callbacks$EarlyStopping( monitor  = 'val_auprc',
                                                   patience =  7,
                                                   restore_best_weights = TRUE,
                                                   mode = 'max')
history <- mod_vae |> fit(
    mds_train,
    epochs=200,
    steps_per_epoch = 50,
    class_weights = c("0"=1/3, "1"=1),
    validation_data=mds_val,
    validation_steps=10,
    )
```